{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Chapter7.PrepareDatasetForLearning import PrepareDatasetForLearning\n",
    "from Chapter7.Evaluation import ClassificationEvaluation\n",
    "from Chapter7.Evaluation import RegressionEvaluation\n",
    "from Chapter7.LearningAlgorithms import ClassificationAlgorithms\n",
    "from Chapter7.LearningAlgorithms import RegressionAlgorithms\n",
    "\n",
    "from util.VisualizeDataset import VisualizeDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform selection on 20% of the dataset and will begin with random forest across all targets: age, activity label, height and weight. Whatever target seems to be most predictable we will apply other algorithms to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>act</th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>trial</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [attitude.roll, attitude.pitch, attitude.yaw, userAcceleration.x, userAcceleration.y, userAcceleration.z, gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z, act, id, weight, height, age, gender, trial, timestamp]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset_gran_250.csv\", index_col=0)\n",
    "display(dataset[dataset.id.isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest - Age - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants in train set:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.]\n",
      "participants in test set:  [19. 20. 21. 22. 23.]\n"
     ]
    }
   ],
   "source": [
    "# we need to split the dataset into 80% trainset and 20% test set\n",
    "# we can't just split it randomly because the data of a single participant needs to stay together\n",
    "train_x = dataset[dataset[\"id\"] < 19].drop(columns=\"age\")\n",
    "train_y = dataset[dataset[\"id\"] < 19].age\n",
    "\n",
    "test_x = dataset[dataset[\"id\"] > 18].drop(columns=\"age\")\n",
    "test_y = dataset[dataset[\"id\"] > 18].age\n",
    "\n",
    "print(\"participants in train set: \", train_x.id.unique())\n",
    "print(\"participants in test set: \", test_x.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict age label with a regression algorithm\n",
    "pred_training_y, pred_test_y = RegressionAlgorithms().random_forest(train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46. 46. 46. ... 28. 28. 28.]\n",
      "[26.5 26.5 26.5 ... 27.8 27.8 27.8] 22884\n",
      "0        25.0\n",
      "250      25.0\n",
      "500      25.0\n",
      "750      25.0\n",
      "1000     25.0\n",
      "         ... \n",
      "66500    18.0\n",
      "66750    18.0\n",
      "67000    18.0\n",
      "67250    18.0\n",
      "67500    18.0\n",
      "Name: age, Length: 22884, dtype: float64 22884\n",
      "MSE:  35.71824244013286\n",
      "MSE and STD:  (35.71824244013286, 42.2945744502565)\n",
      "MAE:  4.475030589057857\n",
      "MAE and STD:  (4.475030589057857, 3.961442847169949)\n",
      "MSE:  0.0\n",
      "MSE and STD:  (0.0, 0.0)\n",
      "MAE:  0.0\n",
      "MAE and STD:  (0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# calculate a score - compare pred_test_y and test_y\n",
    "print(pred_training_y)\n",
    "print(pred_test_y, len(pred_test_y))\n",
    "print(test_y, len(test_y))\n",
    "\n",
    "# for the sake of completeness also compare pred_training_y and train_y\n",
    "evaluator_age = RegressionEvaluation()\n",
    "print(\"MSE: \", evaluator_age.mean_squared_error(test_y, pred_test_y))\n",
    "print(\"MSE and STD: \", evaluator_age.mean_squared_error_with_std(test_y, pred_test_y))\n",
    "print(\"MAE: \", evaluator_age.mean_absolute_error(test_y, pred_test_y))\n",
    "print(\"MAE and STD: \", evaluator_age.mean_absolute_error_with_std(test_y, pred_test_y))\n",
    "\n",
    "print(\"MSE: \", evaluator_age.mean_squared_error(train_y, pred_training_y))\n",
    "print(\"MSE and STD: \", evaluator_age.mean_squared_error_with_std(train_y, pred_training_y))\n",
    "print(\"MAE: \", evaluator_age.mean_absolute_error(train_y, pred_training_y))\n",
    "print(\"MAE and STD: \", evaluator_age.mean_absolute_error_with_std(train_y, pred_training_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest - Label - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants in train set:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.]\n",
      "participants in test set:  [19. 20. 21. 22. 23.]\n"
     ]
    }
   ],
   "source": [
    "# we need to split the dataset into 80% trainset and 20% test set\n",
    "# we can't just split it randomly because the data of a single participant needs to stay together\n",
    "train_x_act = dataset[dataset[\"id\"] < 19].drop(columns=\"act\")\n",
    "train_y_act = dataset[dataset[\"id\"] < 19].act\n",
    "\n",
    "test_x_act = dataset[dataset[\"id\"] > 18].drop(columns=\"act\")\n",
    "test_y_act = dataset[dataset[\"id\"] > 18].act\n",
    "\n",
    "print(\"participants in train set: \", train_x_act.id.unique())\n",
    "print(\"participants in test set: \", test_x_act.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict activity label with a classification algorithm\n",
    "pred_training_y_act, pred_test_y_act, frame_prob_training_y_act, frame_prob_test_y_act = ClassificationAlgorithms().random_forest(train_x_act, train_y_act, test_x_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 5. 5. 5.] 22884\n",
      "0        0.0\n",
      "250      0.0\n",
      "500      0.0\n",
      "750      0.0\n",
      "1000     0.0\n",
      "        ... \n",
      "66500    5.0\n",
      "66750    5.0\n",
      "67000    5.0\n",
      "67250    5.0\n",
      "67500    5.0\n",
      "Name: act, Length: 22884, dtype: float64 22884\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "Accuracy  0.9743488900541863\n",
      "Precision:  [1.         0.9759542  0.9529511  0.90468227 1.         0.99648252]\n",
      "Recall:  [0.93599637 0.93938281 0.98073586 0.94497817 0.9913573  1.        ]\n",
      "f1:  [0.96694021 0.95731936 0.96664386 0.92439129 0.99565989 0.99823816]\n",
      "Confusion Matrix \n",
      " [[2062   54   31   56    0    0]\n",
      " [   0 2557   97   53    0   15]\n",
      " [   0    0 5651  110    0    1]\n",
      " [   0    5  120 2164    0    1]\n",
      " [   0    4   31    9 5047    0]\n",
      " [   0    0    0    0    0 4816]]\n"
     ]
    }
   ],
   "source": [
    "# calculate a score - compare pred_test_y and test_y\n",
    "print(pred_test_y_act, len(pred_test_y_act))\n",
    "print(test_y_act, len(test_y_act))\n",
    "print(test_y_act.unique())\n",
    "# for the sake of completeness also compare pred_training_y and train_y\n",
    "evaluator_label = ClassificationEvaluation()\n",
    "print(\"Accuracy \", evaluator_label.accuracy(test_y_act, pred_test_y_act))\n",
    "print(\"Precision: \", evaluator_label.precision(test_y_act, pred_test_y_act))\n",
    "print(\"Recall: \", evaluator_label.recall(test_y_act, pred_test_y_act))\n",
    "print(\"f1: \", evaluator_label.f1(test_y_act, pred_test_y_act))\n",
    "print(\"Confusion Matrix \\n\", evaluator_label.confusion_matrix(test_y_act, pred_test_y_act, test_y_act.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest - Weight - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants in train set:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.]\n",
      "participants in test set:  [19. 20. 21. 22. 23.]\n"
     ]
    }
   ],
   "source": [
    "# we need to split the dataset into 80% trainset and 20% test set\n",
    "# we can't just split it randomly because the data of a single participant needs to stay together\n",
    "train_x_weight = dataset[dataset[\"id\"] < 19].drop(columns=\"weight\")\n",
    "train_y_weight = dataset[dataset[\"id\"] < 19].weight\n",
    "\n",
    "test_x_weight = dataset[dataset[\"id\"] > 18].drop(columns=\"weight\")\n",
    "test_y_weight = dataset[dataset[\"id\"] > 18].weight\n",
    "\n",
    "print(\"participants in train set: \", train_x_weight.id.unique())\n",
    "print(\"participants in test set: \", test_x_weight.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_training_y_weight, pred_test_y_weight = RegressionAlgorithms().random_forest(train_x_weight, train_y_weight, test_x_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 88.  52. 100.  68.  74.]\n",
      "[76. 76. 76. ... 96. 96. 96.]\n",
      "MSE:  405.3278727495194\n",
      "MSE and STD:  (405.3278727495194, 307.08189015325604)\n",
      "MAE:  17.832179688865583\n",
      "MAE and STD:  (17.832179688865583, 9.345857753837656)\n"
     ]
    }
   ],
   "source": [
    "# calculate a score - compare pred_test_y and test_y\n",
    "print(test_y_weight.unique())\n",
    "# print(pred_test_y_weight)\n",
    "\n",
    "evaluator_weight = RegressionEvaluation()\n",
    "print(\"MSE: \", evaluator_weight.mean_squared_error(test_y_weight, pred_test_y_weight))\n",
    "print(\"MSE and STD: \", evaluator_weight.mean_squared_error_with_std(test_y_weight, pred_test_y_weight))\n",
    "print(\"MAE: \", evaluator_weight.mean_absolute_error(test_y_weight, pred_test_y_weight))\n",
    "print(\"MAE and STD: \", evaluator_weight.mean_absolute_error_with_std(test_y_weight, pred_test_y_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest - Gender - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants in train set:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.]\n",
      "participants in test set:  [19. 20. 21. 22. 23.]\n"
     ]
    }
   ],
   "source": [
    "# we need to split the dataset into 80% trainset and 20% test set\n",
    "# we can't just split it randomly because the data of a single participant needs to stay together\n",
    "train_x_gender = dataset[dataset[\"id\"] < 19].drop(columns=\"gender\")\n",
    "train_y_gender = dataset[dataset[\"id\"] < 19].gender\n",
    "\n",
    "test_x_gender = dataset[dataset[\"id\"] > 18].drop(columns=\"gender\")\n",
    "test_y_gender = dataset[dataset[\"id\"] > 18].gender\n",
    "\n",
    "print(\"participants in train set: \", train_x_weight.id.unique())\n",
    "print(\"participants in test set: \", test_x_weight.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_training_y_gender, pred_test_y_gender, frame_prob_training_y_gender, frame_prob_test_y_gender = ClassificationAlgorithms().random_forest(train_x_gender, train_y_gender, test_x_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7587397308162909\n",
      "Precision:  [0.60502218 1.        ]\n",
      "Recall:  [1.         0.61731476]\n",
      "f1:  [0.7539113  0.76338233]\n",
      "Confusion Matrix \n",
      " [[8906 5521]\n",
      " [   0 8457]]\n"
     ]
    }
   ],
   "source": [
    "# for the sake of completeness also compare pred_training_y and train_y\n",
    "evaluator_gender = ClassificationEvaluation()\n",
    "print(\"Accuracy \", evaluator_gender.accuracy(test_y_gender, pred_test_y_gender))\n",
    "print(\"Precision: \", evaluator_gender.precision(test_y_gender, pred_test_y_gender))\n",
    "print(\"Recall: \", evaluator_gender.recall(test_y_gender, pred_test_y_gender))\n",
    "print(\"f1: \", evaluator_gender.f1(test_y_gender, pred_test_y_gender))\n",
    "print(\"Confusion Matrix \\n\", evaluator_gender.confusion_matrix(test_y_gender, pred_test_y_gender, test_y_gender.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "#### Initial Train split for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.sample(frac=0.2,random_state=200)\n",
    "train_x = train.drop(columns=['act'])\n",
    "train_y = train['act']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " selected_features, ordered_features, ordered_scores = FeatureSelectionClassification().forward_selection(max_features, train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments - By Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [dataset[dataset['trial']==i] for i in dataset['trial'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_alg = ClassificationAlgorithms()\n",
    "\n",
    "def generate_sets(data_set):\n",
    "    train=dataset.sample(frac=0.3) #random state is a seed value\n",
    "    test=dataset.drop(train.index)\n",
    "    test= test.sample(frac=0.3)\n",
    "\n",
    "    train_y = train['act']\n",
    "    train_X = train.drop(columns=['act'])\n",
    "    test_y = test['act']\n",
    "    test_X = test.drop(columns=['act'])\n",
    "    \n",
    "    return train_y, train_X, test_y, test_X\n",
    "\n",
    "\n",
    "def train_classification(train_y, train_X, test_y, test_X, class_alg):\n",
    "    pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y = class_alg.random_forest(train_X, train_y, test_X)\n",
    "    return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y\n",
    "\n",
    "def evaluate_classifcation(y_true, y_pred):\n",
    "    evaluation = ClassificationEvaluation()\n",
    "    return evaluation.accuracy(y_true, y_pred), evaluation.precision(y_true, y_pred), evaluation.recall(y_true, y_pred), evaluation.f1(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest for the labels by trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "prec = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for subset in trials:\n",
    "    train_y, train_X, test_y, test_X = generate_sets(subset)\n",
    "    pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y = train_classification(train_y, train_X, test_y, test_X, class_alg)\n",
    "    accuracy, precision, recall, f1_ = evaluate_classifcation(test_y, pred_test_y)\n",
    "    acc.append(accuracy)\n",
    "    prec.append(precision)\n",
    "    recall.append(recall)\n",
    "    f1.append(f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
