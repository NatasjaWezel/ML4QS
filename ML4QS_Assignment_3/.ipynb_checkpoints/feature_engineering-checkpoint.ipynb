{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset_gran_250.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "milliseconds_per_instance = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for computation\n",
    "To optimally use our resources the trials per individual will be analysed independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chapter4.FrequencyAbstraction import FourierTransformation\n",
    "\n",
    "\n",
    "FreqAbs = FourierTransformation()\n",
    "fs = float(1000)/milliseconds_per_instance\n",
    "\n",
    "periodic_predictor_cols = list(dataset.columns[:12])\n",
    "\n",
    "\n",
    "average_t_per_100_rows = []\n",
    "\n",
    "def do_freq_abstract_for_trial_participant_and_save(trial, participant):\n",
    "    \"\"\"\n",
    "    Does freq abstrac on a single participant for a single trial. After inference results\n",
    "    are saved to a individual csv for later fusing results.\n",
    "    \"\"\"\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    print(f'Worker doing trial {trial} and participant {participant}')\n",
    "    \n",
    "    ds = dataset[dataset.trial.eq(trial)][dataset.id.eq(participant)]\n",
    "    \n",
    "#     print(f'Working on dataset of shape {ds.shape}')\n",
    "    \n",
    "    try:\n",
    "        expected_run_time = sum(average_t_per_100_rows)/len(average_t_per_100_rows) * (ds.shape[0]/100)\n",
    "    except:\n",
    "         expected_run_time = 'UNKNOWN'\n",
    "    \n",
    "#     print(f'Expected run time: {expected_run_time} s')\n",
    "    \n",
    "    my_set = FreqAbs.abstract_frequency(ds, periodic_predictor_cols, int(float(10000)/milliseconds_per_instance), fs)\n",
    "    \n",
    "    my_set.to_csv(f'freq_abstraction_csvs/trial_{trial}_participant_{participant}.csv')\n",
    "    t_done = time.time()\n",
    "    total_time = t_done-t_start\n",
    "    print(f'Took {total_time} seconds')\n",
    "    run_time_per_row = total_time/ds.shape[0] if ds.shape[0] else 0\n",
    "    average_t_per_100_rows.append(100*run_time_per_row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2. 11.  3.  4.]\n",
      "[12.  7.  8. 15.  9.]\n",
      "[16.  6. 14.  5. 13.]\n"
     ]
    }
   ],
   "source": [
    "# divide and conquer\n",
    "participants = dataset.id.unique()\n",
    "\n",
    "cormac_trials = dataset.trial.unique()[:5]\n",
    "abel_trials = dataset.trial.unique()[5:10]\n",
    "natasja_trials = dataset.trial.unique()[10:15]\n",
    "\n",
    "print(cormac_trials)\n",
    "print(abel_trials)\n",
    "print(natasja_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cormac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker doing trial 1.0 and participant 0.0\n",
      "Worker doing trial 1.0 and participant 4.0\n",
      "Worker doing trial 1.0 and participant 8.0\n",
      "Worker doing trial 1.0 and participant 12.0\n",
      "Worker doing trial 1.0 and participant 16.0\n",
      "Worker doing trial 1.0 and participant 20.0\n",
      "Worker doing trial 2.0 and participant 0.0\n",
      "Worker doing trial 2.0 and participant 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset of shape (175, 21)\n",
      "Working on dataset of shape (141, 21)\n",
      "Working on dataset of shape (127, 21)\n",
      "Working on dataset of shape (167, 21)\n",
      "Working on dataset of shape (167, 21)\n",
      "Working on dataset of shape (233, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/natasja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Working on dataset of shape (197, 21)\n",
      "Working on dataset of shape (173, 21)\n",
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Expected run time: UNKNOWN s\n",
      "Took 14.865007162094116 seconds\n",
      "Worker doing trial 1.0 and participant 13.0\n",
      "Working on dataset of shape (138, 21)\n",
      "Expected run time: 16.152527467472346 s\n",
      "Took 17.22282838821411 seconds\n",
      "Worker doing trial 1.0 and participant 1.0\n",
      "Working on dataset of shape (172, 21)\n",
      "Expected run time: 21.00940767923991 s\n",
      "Took 23.300018548965454 seconds\n",
      "Worker doing trial 1.0 and participant 17.0\n",
      "Working on dataset of shape (236, 21)\n",
      "Expected run time: 32.92697232069369 s\n",
      "Took 24.712753534317017 seconds\n",
      "Worker doing trial 1.0 and participant 9.0\n",
      "Working on dataset of shape (215, 21)\n",
      "Expected run time: 31.815820418432086 s\n",
      "Took 25.37162709236145 seconds\n",
      "Worker doing trial 1.0 and participant 5.0\n",
      "Working on dataset of shape (172, 21)\n",
      "Expected run time: 24.936684913635254 s\n",
      "Took 25.570797443389893 seconds\n",
      "Worker doing trial 2.0 and participant 5.0\n",
      "Working on dataset of shape (199, 21)\n",
      "Expected run time: 29.413807463783748 s\n",
      "Took 32.064406871795654 seconds\n",
      "Worker doing trial 2.0 and participant 1.0\n",
      "Working on dataset of shape (212, 21)\n",
      "Expected run time: 34.50585917167857 s\n",
      "Took 22.4243905544281 seconds\n",
      "Worker doing trial 1.0 and participant 14.0\n",
      "Working on dataset of shape (142, 21)\n",
      "Expected run time: 19.84754477938356 s\n",
      "Took 39.12745451927185 seconds\n",
      "Worker doing trial 1.0 and participant 21.0\n",
      "Working on dataset of shape (146, 21)\n",
      "Expected run time: 24.51763244555232 s\n"
     ]
    }
   ],
   "source": [
    "with Pool(processes=cpu_count()) as p:\n",
    "    r = p.starmap(do_freq_abstract_for_trial_participant_and_save, itertools.product(cormac_trials, participants))\n",
    "    print(r)\n",
    "\n",
    "print('All done now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=cpu_count()) as p:\n",
    "    r = p.starmap(do_freq_abstract_for_trial_participant_and_save, itertools.product(abel_trials, participants))\n",
    "    print(r)\n",
    "print('All done now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natasja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=cpu_count()) as p:\n",
    "    r = p.starmap(do_freq_abstract_for_trial_participant_and_save, itertools.product(natasja_trials, participants))\n",
    "    print(r)\n",
    "\n",
    "print('All done now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for csv_file_freq_abs in glob.glob('freq_abstraction_trial_*_participant_*.csv'):\n",
    "    datasets.append(pd.read_csv(csv_file_freq_abs))\n",
    "\n",
    "    \n",
    "    \n",
    "dataset = pd.concat(datasets)\n",
    "\n",
    "dataset.to_csv(\"dataset_engineered_features.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
